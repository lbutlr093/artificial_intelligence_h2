{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /Users/lbutler/anaconda3/lib/python3.7/site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/lbutler/anaconda3/lib/python3.7/site-packages (from keras) (1.17.0)\n",
      "Requirement already satisfied: h5py in /Users/lbutler/anaconda3/lib/python3.7/site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: pyyaml in /Users/lbutler/anaconda3/lib/python3.7/site-packages (from keras) (5.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/lbutler/anaconda3/lib/python3.7/site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/lbutler/anaconda3/lib/python3.7/site-packages (from keras) (1.3.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/lbutler/anaconda3/lib/python3.7/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/lbutler/anaconda3/lib/python3.7/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: tensorflow in /Users/lbutler/anaconda3/lib/python3.7/site-packages (1.14.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /Users/lbutler/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.8.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/lbutler/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.33.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/lbutler/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: gast>=0.2.0 in /Users/lbutler/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/lbutler/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/lbutler/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Users/lbutler/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.8.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /Users/lbutler/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.1.7)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /Users/lbutler/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /Users/lbutler/anaconda3/lib/python3.7/site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/lbutler/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.11.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/lbutler/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/lbutler/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.23.0)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /Users/lbutler/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /Users/lbutler/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: h5py in /Users/lbutler/anaconda3/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow) (2.9.0)\n",
      "Requirement already satisfied: setuptools in /Users/lbutler/anaconda3/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow) (41.2.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/lbutler/anaconda3/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/lbutler/anaconda3/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "## install\n",
    "## uncomment below for installing the first time within jupyter lab notebook:\n",
    "#!pip install keras\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>k</th>\n",
       "      <th>l</th>\n",
       "      <th>m</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>222</td>\n",
       "      <td>31.189189</td>\n",
       "      <td>40.342342</td>\n",
       "      <td>35.579087</td>\n",
       "      <td>8.883917</td>\n",
       "      <td>0.968325</td>\n",
       "      <td>-80.113673</td>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>16.812471</td>\n",
       "      <td>0.816176</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>78.591</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73</td>\n",
       "      <td>29.493151</td>\n",
       "      <td>271.397260</td>\n",
       "      <td>15.517202</td>\n",
       "      <td>6.407490</td>\n",
       "      <td>0.910764</td>\n",
       "      <td>76.042946</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>9.640876</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>39.217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256</td>\n",
       "      <td>58.816406</td>\n",
       "      <td>289.941406</td>\n",
       "      <td>37.226013</td>\n",
       "      <td>9.863895</td>\n",
       "      <td>0.964256</td>\n",
       "      <td>85.324742</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>18.054067</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.562637</td>\n",
       "      <td>89.111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126</td>\n",
       "      <td>71.023810</td>\n",
       "      <td>477.412698</td>\n",
       "      <td>13.112980</td>\n",
       "      <td>12.790672</td>\n",
       "      <td>0.220351</td>\n",
       "      <td>63.523477</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>12.666025</td>\n",
       "      <td>0.881119</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>43.832</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>225</td>\n",
       "      <td>90.808889</td>\n",
       "      <td>541.946667</td>\n",
       "      <td>44.463110</td>\n",
       "      <td>7.858879</td>\n",
       "      <td>0.984256</td>\n",
       "      <td>-52.874983</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>16.925688</td>\n",
       "      <td>0.728155</td>\n",
       "      <td>0.252525</td>\n",
       "      <td>90.072</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a          b           c          d          e         f          g    h  \\\n",
       "0  222  31.189189   40.342342  35.579087   8.883917  0.968325 -80.113673  222   \n",
       "1   73  29.493151  271.397260  15.517202   6.407490  0.910764  76.042946   73   \n",
       "2  256  58.816406  289.941406  37.226013   9.863895  0.964256  85.324742  256   \n",
       "3  126  71.023810  477.412698  13.112980  12.790672  0.220351  63.523477  126   \n",
       "4  225  90.808889  541.946667  44.463110   7.858879  0.984256 -52.874983  225   \n",
       "\n",
       "   i          j         k         l       m  n  \n",
       "0  1  16.812471  0.816176  0.578125  78.591  0  \n",
       "1  1   9.640876  0.858824  0.608333  39.217  0  \n",
       "2  1  18.054067  0.752941  0.562637  89.111  0  \n",
       "3  1  12.666025  0.881119  0.646154  43.832  0  \n",
       "4  1  16.925688  0.728155  0.252525  90.072  7  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Set up the workbook and load the data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data_df = pd.read_csv('CellDNA.csv')\n",
    "#data_df = pd.read_csv(\"C:\\\\tmp\\\\CellDNA.csv\")\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a # unique vals: 363\n",
      "b # unique vals: 1186\n",
      "c # unique vals: 1186\n",
      "d # unique vals: 1186\n",
      "e # unique vals: 1186\n",
      "f # unique vals: 1186\n",
      "g # unique vals: 1186\n",
      "h # unique vals: 366\n",
      "i # unique vals: 20\n",
      "j # unique vals: 363\n",
      "k # unique vals: 1067\n",
      "l # unique vals: 1057\n",
      "m # unique vals: 1105\n",
      "\n",
      "20 unique values for \"i\", I wonder what is going on?\n",
      "\n",
      "Maximum value for i: 1\n",
      "Minimum value for i: -26\n",
      "Counter({1: 1016, 0: 117, -1: 31, -2: 12, -3: 10, -4: 8, -6: 6, -7: 3, -5: 2, -11: 2, -15: 1, -12: 1, -25: 1, -14: 1, -24: 1, -26: 1, -9: 1, -18: 1, -17: 1, -21: 1})\n"
     ]
    }
   ],
   "source": [
    "## Lets explore the features\n",
    "print(\"a # unique vals: \" + str(len(data_df[\"a\"].unique())))\n",
    "print(\"b # unique vals: \" + str(len(data_df[\"b\"].unique())))\n",
    "print(\"c # unique vals: \" + str(len(data_df[\"c\"].unique())))\n",
    "print(\"d # unique vals: \" + str(len(data_df[\"d\"].unique())))\n",
    "print(\"e # unique vals: \" + str(len(data_df[\"e\"].unique())))\n",
    "print(\"f # unique vals: \" + str(len(data_df[\"f\"].unique())))\n",
    "print(\"g # unique vals: \" + str(len(data_df[\"g\"].unique())))\n",
    "print(\"h # unique vals: \" + str(len(data_df[\"h\"].unique())))\n",
    "print(\"i # unique vals: \" + str(len(data_df[\"i\"].unique())))\n",
    "print(\"j # unique vals: \" + str(len(data_df[\"j\"].unique())))\n",
    "print(\"k # unique vals: \" + str(len(data_df[\"k\"].unique())))\n",
    "print(\"l # unique vals: \" + str(len(data_df[\"l\"].unique())))\n",
    "print(\"m # unique vals: \" + str(len(data_df[\"m\"].unique())))\n",
    "\n",
    "## One of these values is weird, lets look at it more\n",
    "print(\"\\n\" + str(len(data_df[\"i\"].unique())) + \" unique values for \\\"i\\\", I wonder what is going on?\\n\")\n",
    "\n",
    "## Min/Max\n",
    "print(\"Maximum value for i: \" + str(data_df[\"i\"].max()))\n",
    "print(\"Minimum value for i: \" + str(data_df[\"i\"].min()))\n",
    "\n",
    "## Distribution\n",
    "i_test = list(data_df[\"i\"])\n",
    "print(Counter(i_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standardize the high-cardinality features from above\n",
    "from sklearn import preprocessing\n",
    "stnd_scaler = preprocessing.StandardScaler()\n",
    "\n",
    "## Standardize the column, drop the old one, replace with the new\n",
    "# a\n",
    "col_to_scale = data_df[[\"a\"]].values.astype(float)\n",
    "a_scaled = stnd_scaler.fit_transform(col_to_scale)\n",
    "data_df = data_df.drop(columns = \"a\")\n",
    "data_df[\"a\"] = a_scaled\n",
    "\n",
    "# b\n",
    "col_to_scale = data_df[[\"b\"]].values.astype(float)\n",
    "b_scaled = stnd_scaler.fit_transform(col_to_scale)\n",
    "data_df = data_df.drop(columns = \"b\")\n",
    "data_df[\"b\"] = b_scaled\n",
    "\n",
    "# c\n",
    "col_to_scale = data_df[[\"c\"]].values.astype(float)\n",
    "c_scaled = stnd_scaler.fit_transform(col_to_scale)\n",
    "data_df = data_df.drop(columns = \"c\")\n",
    "data_df[\"c\"] = c_scaled\n",
    "\n",
    "# d\n",
    "col_to_scale = data_df[[\"d\"]].values.astype(float)\n",
    "d_scaled = stnd_scaler.fit_transform(col_to_scale)\n",
    "data_df = data_df.drop(columns = \"d\")\n",
    "data_df[\"d\"] = d_scaled\n",
    "\n",
    "# e\n",
    "col_to_scale = data_df[[\"e\"]].values.astype(float)\n",
    "e_scaled = stnd_scaler.fit_transform(col_to_scale)\n",
    "data_df = data_df.drop(columns = \"e\")\n",
    "data_df[\"e\"] = e_scaled\n",
    "\n",
    "#f\n",
    "col_to_scale = data_df[[\"f\"]].values.astype(float)\n",
    "f_scaled = stnd_scaler.fit_transform(col_to_scale)\n",
    "data_df = data_df.drop(columns = \"f\")\n",
    "data_df[\"f\"] = f_scaled\n",
    "\n",
    "# g\n",
    "col_to_scale = data_df[[\"g\"]].values.astype(float)\n",
    "g_scaled = stnd_scaler.fit_transform(col_to_scale)\n",
    "data_df = data_df.drop(columns = \"g\")\n",
    "data_df[\"g\"] = g_scaled\n",
    "\n",
    "# h\n",
    "col_to_scale = data_df[[\"h\"]].values.astype(float)\n",
    "h_scaled = stnd_scaler.fit_transform(col_to_scale)\n",
    "data_df = data_df.drop(columns = \"h\")\n",
    "data_df[\"h\"] = h_scaled\n",
    "\n",
    "# do nothing to i in this section\n",
    "\n",
    "# j\n",
    "col_to_scale = data_df[[\"j\"]].values.astype(float)\n",
    "j_scaled = stnd_scaler.fit_transform(col_to_scale)\n",
    "data_df = data_df.drop(columns = \"j\")\n",
    "data_df[\"j\"] = j_scaled\n",
    "\n",
    "# k\n",
    "col_to_scale = data_df[[\"k\"]].values.astype(float)\n",
    "k_scaled = stnd_scaler.fit_transform(col_to_scale)\n",
    "data_df = data_df.drop(columns = \"k\")\n",
    "data_df[\"k\"] = k_scaled\n",
    "\n",
    "# l\n",
    "col_to_scale = data_df[[\"l\"]].values.astype(float)\n",
    "l_scaled = stnd_scaler.fit_transform(col_to_scale)\n",
    "data_df = data_df.drop(columns = \"l\")\n",
    "data_df[\"l\"] = l_scaled\n",
    "\n",
    "# m\n",
    "col_to_scale = data_df[[\"m\"]].values.astype(float)\n",
    "m_scaled = stnd_scaler.fit_transform(col_to_scale)\n",
    "data_df = data_df.drop(columns = \"m\")\n",
    "data_df[\"m\"] = m_scaled\n",
    "\n",
    "# n - TARGET\n",
    "# target: 0 -> 0, all else -> 1\n",
    "data_df[\"target\"] = data_df[\"n\"].apply(lambda x: 0 if x == 0 else 1)\n",
    "data_df = data_df.drop(columns = \"n\")\n",
    "#display(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape: (1217, 32)\n"
     ]
    }
   ],
   "source": [
    "## OneHotEncode the remaining feature\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# i - Encode and drop one column (n - 1)\n",
    "labelencoder_i = LabelEncoder()\n",
    "data_df[\"i\"] = labelencoder_i.fit_transform(data_df[\"i\"].astype(str))\n",
    "onehotencoder_i = OneHotEncoder(categorical_features=[0], sparse=False)\n",
    "i_ohe = onehotencoder_i.fit_transform(data_df[\"i\"].values.reshape(-1,1))\n",
    "\n",
    "## Drop one element from the array (n - 1 columns kept when OHE)\n",
    "i_ohe = pd.DataFrame(i_ohe[:, 1:])\n",
    "\n",
    "## Drop the previous \"i\"\n",
    "data_df = data_df.drop(columns = \"i\")\n",
    "\n",
    "## Concatenate the original data frame and the OneHotEncoded element together\n",
    "data_df = pd.concat((data_df, i_ohe), axis = 1)\n",
    "\n",
    "print(\"New shape: \" + str(data_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current column order: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'target', 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "new column order: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 'target']\n"
     ]
    }
   ],
   "source": [
    "## Clean-up the dataset and move the original target back to the last position in the dataframe\n",
    "cols = data_df.columns.tolist()\n",
    "print(\"current column order: \" + str(cols))\n",
    "\n",
    "## Pop \"n\" column and put it on the end\n",
    "cols.insert(len(cols), cols.pop(cols.index('target')))\n",
    "\n",
    "## re-index the dataframe\n",
    "print(\"new column order: \" + str(cols))\n",
    "data_df = data_df.reindex(columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1217, 31)\n",
      "y shape: (1217,)\n"
     ]
    }
   ],
   "source": [
    "## Split the data into X/y train/test\n",
    "X = data_df.iloc[:, :-1].values\n",
    "y = data_df.iloc[:, -1].values\n",
    "\n",
    "print(\"X shape: \" + str(X.shape))\n",
    "print(\"y shape: \" + str(y.shape))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define model evaluation metrics for each keras epoch\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*  ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100, batch: 20, dropout: 0.0, optimizer: rmsprop\n",
      "epoch: 100, batch: 20, dropout: 0.0, optimizer: adam\n",
      "epoch: 100, batch: 20, dropout: 0.1, optimizer: rmsprop\n",
      "epoch: 100, batch: 20, dropout: 0.1, optimizer: adam\n",
      "epoch: 100, batch: 20, dropout: 0.2, optimizer: rmsprop\n",
      "epoch: 100, batch: 20, dropout: 0.2, optimizer: adam\n",
      "epoch: 100, batch: 30, dropout: 0.0, optimizer: rmsprop\n",
      "epoch: 100, batch: 30, dropout: 0.0, optimizer: adam\n",
      "epoch: 100, batch: 30, dropout: 0.1, optimizer: rmsprop\n",
      "epoch: 100, batch: 30, dropout: 0.1, optimizer: adam\n",
      "epoch: 100, batch: 30, dropout: 0.2, optimizer: rmsprop\n",
      "epoch: 100, batch: 30, dropout: 0.2, optimizer: adam\n",
      "epoch: 100, batch: 40, dropout: 0.0, optimizer: rmsprop\n",
      "epoch: 100, batch: 40, dropout: 0.0, optimizer: adam\n",
      "epoch: 100, batch: 40, dropout: 0.1, optimizer: rmsprop\n",
      "epoch: 100, batch: 40, dropout: 0.1, optimizer: adam\n",
      "epoch: 100, batch: 40, dropout: 0.2, optimizer: rmsprop\n",
      "epoch: 100, batch: 40, dropout: 0.2, optimizer: adam\n",
      "epoch: 200, batch: 20, dropout: 0.0, optimizer: rmsprop\n",
      "epoch: 200, batch: 20, dropout: 0.0, optimizer: adam\n",
      "epoch: 200, batch: 20, dropout: 0.1, optimizer: rmsprop\n",
      "epoch: 200, batch: 20, dropout: 0.1, optimizer: adam\n",
      "epoch: 200, batch: 20, dropout: 0.2, optimizer: rmsprop\n",
      "epoch: 200, batch: 20, dropout: 0.2, optimizer: adam\n",
      "epoch: 200, batch: 30, dropout: 0.0, optimizer: rmsprop\n",
      "epoch: 200, batch: 30, dropout: 0.0, optimizer: adam\n",
      "epoch: 200, batch: 30, dropout: 0.1, optimizer: rmsprop\n",
      "epoch: 200, batch: 30, dropout: 0.1, optimizer: adam\n",
      "epoch: 200, batch: 30, dropout: 0.2, optimizer: rmsprop\n",
      "epoch: 200, batch: 30, dropout: 0.2, optimizer: adam\n",
      "epoch: 200, batch: 40, dropout: 0.0, optimizer: rmsprop\n",
      "epoch: 200, batch: 40, dropout: 0.0, optimizer: adam\n"
     ]
    }
   ],
   "source": [
    "## Find the best model\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "epoch = [100, 200]\n",
    "batch = [20, 30, 40]\n",
    "dropout = [0.0, 0.1, 0.2]\n",
    "optimizer = ['rmsprop', 'adam']\n",
    "\n",
    "max_epoch = 0\n",
    "max_batch = 0\n",
    "max_dropout = 0\n",
    "max_optimizer = ''\n",
    "max_accuracy = 0\n",
    "max_precision = 0\n",
    "max_recall = 0\n",
    "\n",
    "output = []\n",
    "start_time = time.time()\n",
    "\n",
    "for e in epoch:\n",
    "    for b in batch:\n",
    "        for d in dropout:\n",
    "            for o in optimizer:\n",
    "                # below used to see progress through each parameter in real-time\n",
    "                print(\"epoch: \" + str(e) + \", batch: \" + str(b) + \", dropout: \" + str(d) + \", optimizer: \" + str(o))\n",
    "                model = Sequential()\n",
    "                model.add(Dense(8, input_dim = 31, kernel_regularizer = regularizers.l2(0.01), activation = 'relu'))\n",
    "                model.add(Dropout(d))\n",
    "                model.add(Dense(6, activation = 'relu'))\n",
    "                model.add(Dropout(d))\n",
    "                model.add(Dense(1, activation = 'sigmoid'))\n",
    "                model.compile(loss = 'binary_crossentropy', optimizer = o, metrics = ['accuracy', f1_m, precision_m, recall_m])\n",
    "                model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = e, batch_size = b, verbose = 0)\n",
    "                #model.summary()\n",
    "                loss, accuracy, f1_score, precision, recall = model.evaluate(X_test, y_test, verbose = 0)\n",
    "                output.append(\"epoch: \" + str(e) \n",
    "                            + \", batch: \" + str(b)\n",
    "                            + \", dropout: \" + str(d)\n",
    "                            + \", accuracy: \" + str(round(accuracy, 5))\n",
    "                            + \", precision: \" + str(round(precision, 5))\n",
    "                            + \", recall: \" + str(round(recall, 5)))\n",
    "                scores = model.evaluate(X_test, y_test, verbose = 0)\n",
    "                if accuracy > max_accuracy:\n",
    "                    max_accuracy = accuracy\n",
    "                    max_precision = precision\n",
    "                    max_recall = recall\n",
    "                    max_epoch = e\n",
    "                    max_batch = b\n",
    "                    max_dropout = d\n",
    "                    max_optimizer = o\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Model Evaluation per model parameter:\")\n",
    "print(*output, sep = \"\\n\")\n",
    "print(\"\\nmax accuracy: \" + str(round(max_accuracy, 5)) \n",
    "          + \", precision: \" + str(round(max_precision, 5)) \n",
    "          + \", recall: \" + str(round(max_recall, 5)) \n",
    "          + \"\\nusing epoch: \" + str(max_epoch) \n",
    "          + \", batch: \" + str(max_batch) \n",
    "          +  \", dropout: \" + str(max_dropout) \n",
    "          + \", optimizer: \" + str(max_optimizer) + \"\\n\")\n",
    "print(\"time in seconds: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using epoch: 100, batch: 40, dropout: 0.2, optimizer: rmsprop\n",
      "Model: \"sequential_270\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_849 (Dense)            (None, 8)                 256       \n",
      "_________________________________________________________________\n",
      "dropout_421 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_850 (Dense)            (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dropout_422 (Dropout)        (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_851 (Dense)            (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 317\n",
      "Trainable params: 317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "time in seconds: 77.78207111358643\n"
     ]
    }
   ],
   "source": [
    "## Use the best results from the previous section\n",
    "import time\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"using epoch: \" + str(max_epoch) + \", batch: \" + str(max_batch) \n",
    "                 + \", dropout: \" + str(max_dropout)  + \", optimizer: \"\n",
    "                 + str(max_optimizer))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim = 31, kernel_regularizer = regularizers.l2(0.01), activation = 'relu'))\n",
    "model.add(Dropout(max_dropout))\n",
    "model.add(Dense(6, activation = 'relu'))\n",
    "model.add(Dropout(max_dropout))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = max_optimizer, metrics = ['accuracy', f1_m, precision_m, recall_m])\n",
    "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = max_epoch, batch_size = max_batch, verbose = 0)\n",
    "model.summary()\n",
    "\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test, y_test, verbose = 0)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"time in seconds: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.91791\n",
      "recall: 0.80504\n",
      "precision: 0.73932\n",
      "f1: 0.73728\n",
      "\n",
      "Confusion Matrix:\n",
      "[[318  18]\n",
      " [ 15  51]]\n"
     ]
    }
   ],
   "source": [
    "## Predict\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred[:,0]\n",
    "\n",
    "## Classes\n",
    "y_classes = model.predict_classes(X_test)\n",
    "y_classes = y_classes[:,0]\n",
    "\n",
    "## Model Evaluation\n",
    "print(\"accuracy: \" + str(round(accuracy, 5)) + \"\\nrecall: \" + str(round(recall, 5)) \n",
    "          + \"\\nprecision: \" + str(round(precision, 5)) + \"\\nf1: \" + str(round(f1_score, 5)))\n",
    "\n",
    "## Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_classes)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.97299\n"
     ]
    }
   ],
   "source": [
    "## ROC/AUC\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for printing in Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, y_pred)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "plt.plot(fpr, tpr, label = \"auc=\" + str(auc))\n",
    "plt.title(\"AUC - ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc = 4)\n",
    "plt.show()\n",
    "           \n",
    "print(\"ROC AUC: \" + str(round(auc, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
